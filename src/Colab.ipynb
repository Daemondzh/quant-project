{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "def create_order_book(df, timestamps):\n",
    "    timestamps = pd.to_datetime(timestamps)\n",
    "    ts_index = 0\n",
    "\n",
    "    # Initialize order book and dictionary to store order books for different timestamps\n",
    "    order_book = pd.DataFrame(columns=['appl_seq_num', 'side', 'price', 'order_qty'])\n",
    "    # bid_side = pd.DataFrame()\n",
    "    new_orders = pd.DataFrame(columns=['appl_seq_num', 'side', 'price', 'order_qty'])\n",
    "    order_books = {ts: None for ts in timestamps}\n",
    "\n",
    "    # Loop through sorted dataframe\n",
    "    for idx, row in df.iterrows():\n",
    "        # If the timestamp of the current row is greater than the current timestamp in the list,\n",
    "        # finalize the order book for the current timestamp, then move to the next timestamp\n",
    "        while ts_index < len(timestamps) and row['transact_time'] > timestamps[ts_index]:\n",
    "            # Concat new orders to the order book\n",
    "            if not new_orders.empty:\n",
    "                order_book = pd.concat([order_book, new_orders], ignore_index=True)\n",
    "                new_orders = new_orders.iloc[0:0]  # Clear new_orders DataFrame\n",
    "\n",
    "            bid_side = order_book[order_book['side'] == 1].sort_values(by='price', ascending=False).head(1)\n",
    "            offer_side = order_book[order_book['side'] == 2].sort_values(by='price', ascending=True).head(1)\n",
    "            order_books[timestamps[ts_index]] = (bid_side, offer_side)\n",
    "            ts_index += 1\n",
    "\n",
    "        if row['order_type'] == '2':  # New order\n",
    "            new_order = pd.DataFrame([row[['appl_seq_num', 'side', 'price', 'order_qty']]])\n",
    "            new_orders = pd.concat([new_orders, new_order], ignore_index=True)\n",
    "        elif row['order_type'] == '1':\n",
    "            new_order = pd.DataFrame([row[['appl_seq_num', 'side', 'price', 'order_qty']]])\n",
    "            if row['side'] == 2:\n",
    "                new_order['price'] = max(new_orders[new_orders['side'] == 1]['price'].max(), order_book[order_book['side'] == 1]['price'].max())\n",
    "            else:\n",
    "                new_order['price'] = min(new_orders[new_orders['side'] == 2]['price'].min(), order_book[order_book['side'] == 2]['price'].min())\n",
    "            new_orders = pd.concat([new_orders, new_order], ignore_index=True)\n",
    "        elif row['order_type'] == 'U':\n",
    "            new_order = pd.DataFrame([row[['appl_seq_num', 'side', 'price', 'order_qty']]])\n",
    "            if row['side'] == 1:\n",
    "                new_order['price'] = max(new_orders[new_orders['side'] == 1]['price'].max(), order_book[order_book['side'] == 1]['price'].max())\n",
    "            else:\n",
    "                new_order['price'] = min(new_orders[new_orders['side'] == 2]['price'].min(), order_book[order_book['side'] == 2]['price'].min())\n",
    "            new_orders = pd.concat([new_orders, new_order], ignore_index=True)\n",
    "        elif row['order_type'] == '4':  # Cancel order\n",
    "            if row['bid_appl_seq_num'] != 0:\n",
    "                new_orders = new_orders[new_orders['appl_seq_num'] != row['bid_appl_seq_num']]\n",
    "                order_book = order_book[order_book['appl_seq_num'] != row['bid_appl_seq_num']]\n",
    "            if row['offer_appl_seq_num'] != 0:\n",
    "                new_orders = new_orders[new_orders['appl_seq_num'] != row['offer_appl_seq_num']]\n",
    "                order_book = order_book[order_book['appl_seq_num'] != row['offer_appl_seq_num']]\n",
    "        elif row['order_type'] == 'F':  # Execute trade\n",
    "            new_orders.loc[new_orders['appl_seq_num'] == row['bid_appl_seq_num'], 'order_qty'] -= row['order_qty']\n",
    "            new_orders.loc[new_orders['appl_seq_num'] == row['offer_appl_seq_num'], 'order_qty'] -= row['order_qty']\n",
    "            new_orders = new_orders[new_orders['order_qty'] > 0]\n",
    "            order_book.loc[order_book['appl_seq_num'] == row['bid_appl_seq_num'], 'order_qty'] -= row['order_qty']\n",
    "            order_book.loc[order_book['appl_seq_num'] == row['offer_appl_seq_num'], 'order_qty'] -= row['order_qty']\n",
    "            order_book = order_book[order_book['order_qty'] > 0]\n",
    "        \n",
    "        if ts_index == len(timestamps):\n",
    "            break\n",
    "\n",
    "    # If there are still timestamps left after looping through the dataframe, finalize the order books for those timestamps\n",
    "    while ts_index < len(timestamps):\n",
    "        # Concat new orders to the order book\n",
    "        if not new_orders.empty:\n",
    "            order_book = pd.concat([order_book, new_orders], ignore_index=True)\n",
    "            new_orders = new_orders.iloc[0:0]  # Clear new_orders DataFrame\n",
    "\n",
    "        bid_side = order_book[order_book['side'] == 1].sort_values(by='price', ascending=False).head(1)\n",
    "        offer_side = order_book[order_book['side'] == 2].sort_values(by='price', ascending=True).head(1)\n",
    "        order_books[timestamps[ts_index]] = (bid_side, offer_side)\n",
    "        ts_index += 1\n",
    "\n",
    "    return order_books\n",
    "\n",
    "\n",
    "# Set the directory where files are stored\n",
    "directory = \"/workspaces/quant-project/data/sz_level3/000069/\"  # Current directory\n",
    "\n",
    "# Create date range\n",
    "date_range = pd.date_range(start=\"2020-01-23\", end=\"2020-07-07\")\n",
    "\n",
    "# Enumerate through each date in the range\n",
    "for date in date_range:\n",
    "    # Format date as a string in the form YYYY-MM-DD\n",
    "    timestamps = []\n",
    "    date_str = date.strftime(\"%Y%m%d\")\n",
    "\n",
    "    # Construct the full path of the file\n",
    "    file_name = \"000069_\"+ date_str+ \".csv.gz\"\n",
    "    file_path = os.path.join(directory, file_name)\n",
    "\n",
    "    # Check if a file with this name exists in the directory\n",
    "    if os.path.isfile(file_path):\n",
    "        do_flag = True\n",
    "        # print(\"File '{file_name}' exists.\")\n",
    "    else:\n",
    "        # print(\"File '{file_name}' does not exist.\")\n",
    "        continue\n",
    "\n",
    "    time_0 = datetime.strptime(\"09:30:00\", '%H:%M:%S').time()\n",
    "    time_1 = datetime.strptime(\"11:30:00\", '%H:%M:%S').time()\n",
    "    start_time = datetime.combine(date, time_0)  # Specify your desired start time\n",
    "    end_time = datetime.combine(date, time_1)  # Specify your desired end time\n",
    "\n",
    "    # Define the time step as 3 seconds\n",
    "    time_step = timedelta(seconds=3)\n",
    "\n",
    "    # Calculate the total number of steps\n",
    "    num_steps = int((end_time - start_time) / time_step) + 1\n",
    "\n",
    "    # Generate and print timestamps\n",
    "    current_time = start_time\n",
    "    for _ in range(num_steps):\n",
    "        timestamps.append(current_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        current_time += time_step\n",
    "\n",
    "    time_0 = datetime.strptime(\"13:00:00\", '%H:%M:%S').time()\n",
    "    time_1 = datetime.strptime(\"15:00:00\", '%H:%M:%S').time()\n",
    "    start_time = datetime.combine(date, time_0)  # Specify your desired start time\n",
    "    end_time = datetime.combine(date, time_1)  # Specify your desired end time\n",
    "\n",
    "    # Calculate the total number of steps\n",
    "    num_steps = int((end_time - start_time) / time_step) + 1\n",
    "\n",
    "    # Generate and print timestamps\n",
    "    current_time = start_time\n",
    "    for _ in range(num_steps):\n",
    "        timestamps.append(current_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        current_time += time_step\n",
    "\n",
    "    df = pd.read_csv(file_path, compression='gzip')\n",
    "    df['transact_time'] = pd.to_datetime(df['transact_time'], format=\"%Y%m%d%H%M%S%f\")\n",
    "    df['price'] = df['price'] / 10000  # Data cleaning, restore the price to its real value\n",
    "    df['order_qty'] = df['order_qty'] / 100  # Data cleaning, restore the order quantity to its real value\n",
    "    stock_code = '000069'\n",
    "    df['stock_code'] = stock_code\n",
    "\n",
    "    order_books = create_order_book(df, timestamps)\n",
    "\n",
    "    for timestamp, (bid_side, offer_side) in order_books.items():\n",
    "        print(\"Order book at\", timestamp)\n",
    "        print(\"Bid side:\")\n",
    "        print(bid_side)\n",
    "        print(\"Offer side:\")\n",
    "        print(offer_side)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Initialize lists for storing data\n",
    "timestamps = []\n",
    "bid_prices = []\n",
    "offer_prices = []\n",
    "bid_qty = []\n",
    "offer_qty = []\n",
    "\n",
    "with open('/workspaces/quant-project/log', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    fake_time = True\n",
    "    for i, line in enumerate(lines):\n",
    "        # Find timestamp\n",
    "        if \"Order book at\" in line:\n",
    "            if fake_time:\n",
    "                fake_time = False\n",
    "            else:\n",
    "                timestamps.append(pd.to_datetime(time))\n",
    "                bid_prices.append(bid_price)\n",
    "                bid_qty.append(bid_order_qty)\n",
    "                offer_prices.append(offer_price)\n",
    "                offer_qty.append(offer_order_qty)\n",
    "            \n",
    "            time = re.findall(\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\", line)[0]\n",
    "            \n",
    "        # Find bid price and quantity\n",
    "        if \"Bid side:\" in line:\n",
    "            bid_line = re.findall(\"\\d+\\.\\d+|\\d+\", lines[i+2])\n",
    "            # print(bid_line)\n",
    "            if not bid_line or fake_time:\n",
    "                fake_time = True\n",
    "                continue\n",
    "            bid_price, bid_order_qty = float(bid_line[3]), float(bid_line[4])\n",
    "            \n",
    "\n",
    "        # Find offer price and quantity\n",
    "        if \"Offer side:\" in line:\n",
    "            offer_line = re.findall(\"\\d+\\.\\d+|\\d+\", lines[i+2])\n",
    "            if not offer_line or fake_time:\n",
    "                fake_time = True\n",
    "                continue\n",
    "            offer_price, offer_order_qty = float(offer_line[3]), float(offer_line[4])\n",
    "    \n",
    "    if fake_time:\n",
    "        fake_time = False\n",
    "    else:\n",
    "        timestamps.append(pd.to_datetime(time))\n",
    "        bid_prices.append(bid_price)\n",
    "        bid_qty.append(bid_order_qty)\n",
    "        offer_prices.append(offer_price)\n",
    "        offer_qty.append(offer_order_qty)\n",
    "\n",
    "# Create a dataframe\n",
    "data = {'Timestamp': timestamps, \n",
    "        'Bid Price': bid_prices, \n",
    "        'Offer Price': offer_prices, \n",
    "        'Bid Quantity': bid_qty, \n",
    "        'Offer Quantity': offer_qty}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv('00069.csv')\n",
    "\n",
    "# Set Timestamp as index\n",
    "df = df.set_index('Timestamp')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=[15,10])\n",
    "plt.grid(True)\n",
    "plt.plot(df['Bid Price'], label='Bid Price', linewidth=2, markersize=12)\n",
    "plt.plot(df['Offer Price'], label='Offer Price', linewidth=2, markersize=12)\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Bid and Offer Prices Over Time', fontsize=20)\n",
    "plt.legend(loc=2)\n",
    "plt.savefig('plot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_order_book(df, timestamps):\n",
    "    timestamps = sorted(pd.to_datetime(timestamps))\n",
    "    ts_index = 0\n",
    "\n",
    "    # Initialize order book and dictionary to store order books for different timestamps\n",
    "    order_book = pd.DataFrame(columns=['appl_seq_num', 'side', 'price', 'order_qty'])\n",
    "    new_orders = pd.DataFrame(columns=['appl_seq_num', 'side', 'price', 'order_qty'])\n",
    "    order_books = {ts: None for ts in timestamps}\n",
    "\n",
    "    # Loop through sorted dataframe\n",
    "    for idx, row in df.iterrows():\n",
    "        # If the timestamp of the current row is greater than the current timestamp in the list,\n",
    "        # finalize the order book for the current timestamp, then move to the next timestamp\n",
    "        while ts_index < len(timestamps) and row['transact_time'] > timestamps[ts_index]:\n",
    "            # Concat new orders to the order book\n",
    "            if not new_orders.empty:\n",
    "                order_book = pd.concat([order_book, new_orders], ignore_index=True)\n",
    "                new_orders = new_orders.iloc[0:0]  # Clear new_orders DataFrame\n",
    "\n",
    "            bid_side = order_book[order_book['side'] == 1].sort_values(by='price', ascending=False).head(10)\n",
    "            offer_side = order_book[order_book['side'] == 2].sort_values(by='price', ascending=True).head(10)\n",
    "            order_books[timestamps[ts_index]] = (bid_side, offer_side)\n",
    "            ts_index += 1\n",
    "\n",
    "        if row['order_type'] == '2':  # New order\n",
    "            new_order = pd.DataFrame([row[['appl_seq_num', 'side', 'price', 'order_qty']]])\n",
    "            new_orders = pd.concat([new_orders, new_order], ignore_index=True)\n",
    "        elif row['order_type'] == '1':\n",
    "            new_order = pd.DataFrame([row[['appl_seq_num', 'side', 'price', 'order_qty']]])\n",
    "            if row['side'] == 2:\n",
    "                new_order['price'] = max(new_orders[new_orders['side'] == 1]['price'].max(), bid_side.iloc[0]['price'])\n",
    "            else:\n",
    "                new_order['price'] = min(new_orders[new_orders['side'] == 2]['price'].min(), offer_side.iloc[0]['price'])\n",
    "            new_orders = pd.concat([new_orders, new_order], ignore_index=True)\n",
    "        elif row['order_type'] == 'U':\n",
    "            new_order = pd.DataFrame([row[['appl_seq_num', 'side', 'price', 'order_qty']]])\n",
    "            if row['side'] == 1:\n",
    "                new_order['price'] = max(new_orders[new_orders['side'] == 1]['price'].max(), bid_side.iloc[0]['price'])\n",
    "            else:\n",
    "                new_order['price'] = min(new_orders[new_orders['side'] == 2]['price'].min(), offer_side.iloc[0]['price'])\n",
    "            new_orders = pd.concat([new_orders, new_order], ignore_index=True)\n",
    "        elif row['order_type'] == '4':  # Cancel order\n",
    "            if row['bid_appl_seq_num'] != 0:\n",
    "                new_orders = new_orders[new_orders['appl_seq_num'] != row['bid_appl_seq_num']]\n",
    "                order_book = order_book[order_book['appl_seq_num'] != row['bid_appl_seq_num']]\n",
    "            if row['offer_appl_seq_num'] != 0:\n",
    "                new_orders = new_orders[new_orders['appl_seq_num'] != row['offer_appl_seq_num']]\n",
    "                order_book = order_book[order_book['appl_seq_num'] != row['offer_appl_seq_num']]\n",
    "        elif row['order_type'] == 'F':  # Execute trade\n",
    "            new_orders.loc[new_orders['appl_seq_num'] == row['bid_appl_seq_num'], 'order_qty'] -= row['order_qty']\n",
    "            new_orders.loc[new_orders['appl_seq_num'] == row['offer_appl_seq_num'], 'order_qty'] -= row['order_qty']\n",
    "            new_orders = new_orders[new_orders['order_qty'] > 0]\n",
    "            order_book.loc[order_book['appl_seq_num'] == row['bid_appl_seq_num'], 'order_qty'] -= row['order_qty']\n",
    "            order_book.loc[order_book['appl_seq_num'] == row['offer_appl_seq_num'], 'order_qty'] -= row['order_qty']\n",
    "            order_book = order_book[order_book['order_qty'] > 0]\n",
    "\n",
    "    # If there are still timestamps left after looping through the dataframe, finalize the order books for those timestamps\n",
    "    while ts_index < len(timestamps):\n",
    "        # Concat new orders to the order book\n",
    "        if not new_orders.empty:\n",
    "            order_book = pd.concat([order_book, new_orders], ignore_index=True)\n",
    "            new_orders = new_orders.iloc[0:0]  # Clear new_orders DataFrame\n",
    "\n",
    "        bid_side = order_book[order_book['side'] == 1].sort_values(by='price', ascending=False).head(10)\n",
    "        offer_side = order_book[order_book['side'] == 2].sort_values(by='price', ascending=True).head(10)\n",
    "        order_books[timestamps[ts_index]] = (bid_side, offer_side)\n",
    "        ts_index += 1\n",
    "\n",
    "    return order_books\n",
    "\n",
    "\n",
    "timestamps = ['2020-01-10 09:30:00', '2020-01-10 10:30:00', '2020-01-10 13:30:00']\n",
    "for stock_code in  ['000069','000566','000876','002304','002841','002918']:\n",
    "    df = pd.read_csv('/workspaces/quant-project/data/sz_level3/'+stock_code+'/'+stock_code+'_20200110.csv.gz', compression='gzip')\n",
    "    df['transact_time'] = pd.to_datetime(df['transact_time'], format=\"%Y%m%d%H%M%S%f\")\n",
    "    df['price'] = df['price'] / 10000  # Data cleaning, restore the price to its real value\n",
    "    df['order_qty'] = df['order_qty'] / 100  # Data cleaning, restore the order quantity to its real value\n",
    "    df['stock_code'] = stock_code\n",
    "\n",
    "    order_books = create_order_book(df, timestamps)\n",
    "\n",
    "    for timestamp, (bid_side, offer_side) in order_books.items():\n",
    "        print('Stock Code:', stock_code)\n",
    "        print(\"Order book at\", timestamp)\n",
    "        print(\"Bid side:\")\n",
    "        print(bid_side)\n",
    "        print(\"Offer side:\")\n",
    "        print(offer_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import mplfinance as mpf\n",
    "import matplotlib as mpl# 用于设置曲线参数\n",
    "from cycler import cycler# 用于定制线条颜色\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#数据清洗：丢弃行，或用上一行的值填充\n",
    "def data_wash(dataset,keepTime=False):\n",
    "    if keepTime:\n",
    "        dataset.fillna(axis=1,method='ffill')\n",
    "    else:\n",
    "        dataset.dropna()\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def import_csv(stock_code):\n",
    "    #time设为index的同时是否保留时间列\n",
    "    df = pd.read_csv(stock_code + '.csv')\n",
    "    #清洗数据\n",
    "    df=data_wash(df,keepTime=False)\n",
    "    df.rename(\n",
    "            columns={\n",
    "            'Timestamp': 'Date', 'Bid Price': 'Open', \n",
    "            'Offer Price': 'High', 'Bid Quantity': 'Low', \n",
    "            'Offer Quantity': 'Close'}, \n",
    "            inplace=True)\n",
    "    # df['Date'] = pd.to_datetime(df['Date'],format='%Y%m%d')    \n",
    "    df.set_index(df['Date'], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# In[361]:\n",
    "\n",
    "\n",
    "def draw_Kline(df,period,symbol):\n",
    "    # 设置基本参数\n",
    "    # type:#绘制图形的类型，有candle, renko, ohlc, line等\n",
    "    # 此处选择candle,即K线图\n",
    "    # mav(moving average):均线类型,此处设置7,30,60日线\n",
    "    # volume:布尔类型，设置是否显示成交量，默认False\n",
    "    # title:设置标题\n",
    "    # y_label:设置纵轴主标题\n",
    "    # y_label_lower:设置成交量图一栏的标题\n",
    "    # figratio:设置图形纵横比\n",
    "    # figscale:设置图形尺寸(数值越大图像质量越高)\n",
    "    kwargs = dict(\n",
    "        type='candle', \n",
    "        mav=(7, 30, 60), \n",
    "        volume=True, \n",
    "        title='\\nA_stock %s candle_line' % (symbol),    \n",
    "        ylabel='OHLC Candles', \n",
    "        ylabel_lower='Shares\\nTraded Volume', \n",
    "        figratio=(15, 10), \n",
    "        figscale=2)\n",
    "\n",
    "    # 设置marketcolors\n",
    "    # up:设置K线线柱颜色，up意为收盘价大于等于开盘价\n",
    "    # down:与up相反，这样设置与国内K线颜色标准相符\n",
    "    # edge:K线线柱边缘颜色(i代表继承自up和down的颜色)，下同。详见官方文档)\n",
    "    # wick:灯芯(上下影线)颜色\n",
    "    # volume:成交量直方图的颜色\n",
    "    # inherit:是否继承，选填\n",
    "    mc = mpf.make_marketcolors(\n",
    "        up='red', \n",
    "        down='green', \n",
    "        edge='i', \n",
    "        wick='i', \n",
    "        volume='in', \n",
    "        inherit=True)\n",
    "\n",
    "    # 设置图形风格\n",
    "    # gridaxis:设置网格线位置\n",
    "    # gridstyle:设置网格线线型\n",
    "    # y_on_right:设置y轴位置是否在右\n",
    "    s = mpf.make_mpf_style(\n",
    "        gridaxis='both', \n",
    "        gridstyle='-.', \n",
    "        y_on_right=False, \n",
    "        marketcolors=mc)\n",
    "\n",
    "    # 设置均线颜色，配色表可见下图\n",
    "    # 建议设置较深的颜色且与红色、绿色形成对比\n",
    "    # 此处设置七条均线的颜色，也可应用默认设置\n",
    "    mpl.rcParams['axes.prop_cycle'] = cycler(\n",
    "        color=['dodgerblue', 'deeppink', \n",
    "        'navy', 'teal', 'maroon', 'darkorange', \n",
    "        'indigo'])\n",
    "    \n",
    "    # 设置线宽\n",
    "    mpl.rcParams['lines.linewidth'] = .5\n",
    "\n",
    "    # 图形绘制\n",
    "    # show_nontrading:是否显示非交易日，默认False\n",
    "    # savefig:导出图片，填写文件名及后缀\n",
    "    mpf.plot(df, \n",
    "        **kwargs, \n",
    "        style=s, \n",
    "        show_nontrading=False,)\n",
    "    mpf.plot(df, \n",
    "        **kwargs, \n",
    "        style=s, \n",
    "        show_nontrading=False,\n",
    "        savefig='A_stock-%s %s_candle_line'\n",
    "        %(symbol, period) + '.jpg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# In[163]:\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# In[320]:\n",
    "\n",
    "\n",
    "#读取数据切割数据集并保存\n",
    "TRAIN_WEIGHT=0.9\n",
    "SEQ_LEN=49\n",
    "N_Pre=10\n",
    "LEARNING_RATE=0.00001\n",
    "BATCH_SIZE=4\n",
    "EPOCH=2\n",
    "\n",
    "symbol = '00069'\n",
    "data = import_csv(symbol)\n",
    "# df_draw=data[-period:]\n",
    "# draw_Kline(df_draw,period,symbol)\n",
    "data.drop(['Num'],axis=1,inplace = True)   \n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_size=int(TRAIN_WEIGHT*(data.shape[0]))\n",
    "train_path=\"stock_daily/stock_train.csv\"\n",
    "test_path=\"stock_daily/stock_test.csv\"\n",
    "Train_data=data[:train_size+SEQ_LEN]\n",
    "Test_data=data[train_size-SEQ_LEN:]\n",
    "Train_data.to_csv(train_path,sep=',',index=False,header=False)\n",
    "Test_data.to_csv(test_path,sep=',',index=False,header=False)\n",
    "\n",
    "\n",
    "# In[321]:\n",
    "\n",
    "\n",
    "mean_list=[]\n",
    "std_list=[]\n",
    "\n",
    "\n",
    "# In[358]:\n",
    "\n",
    "\n",
    "#完成数据集类\n",
    "class Stock_Data(Dataset):\n",
    "    def __init__(self,train=True,transform=None):        \n",
    "        if train==True:\n",
    "            train_path=\"stock_daily/stock_train.csv\"\n",
    "            with open(train_path) as f:\n",
    "                self.data = np.genfromtxt(f,delimiter = \",\")\n",
    "                #可以注释\n",
    "                #addi=np.zeros((self.data.shape[0],1))\n",
    "                #self.data=np.concatenate((self.data,addi),axis=1)\n",
    "                self.data=self.data[:,1:5]\n",
    "            #for i in range(self.data.shape[0]-SEQ_LEN):\n",
    "            #    self.data[i+SEQ_LEN,1]=(sum(self.data[i+SEQ_LEN:i+SEQ_LEN+N_Pre,1])/N_Pre-self.data[i+SEQ_LEN-1,1])/self.data[i+SEQ_LEN-1,1]\n",
    "            #    self.data[i+SEQ_LEN,2]=(sum(self.data[i+SEQ_LEN:i+SEQ_LEN+N_Pre,2])/N_Pre-self.data[i+SEQ_LEN-1,2])/self.data[i+SEQ_LEN-1,2]\n",
    "            self.label=torch.rand(self.data.shape[0]-SEQ_LEN,1)\n",
    "            # y = []\n",
    "            # for i in range(self.data.shape[0]-SEQ_LEN):\n",
    "            #     y.append((np.mean(self.data[i+SEQ_LEN:i+SEQ_LEN+N_Pre,0])-self.data[i+SEQ_LEN-1,0])/self.data[i+SEQ_LEN-1,0])\n",
    "            #    self.label[i,:]=(np.mean(self.data[i+SEQ_LEN:i+SEQ_LEN+N_Pre,0])-self.data[i+SEQ_LEN-1,0])/self.data[i+SEQ_LEN-1,0]\n",
    "            # y = np.array(y).astype(np.float64)\n",
    "            # y_std = np.std(y)\n",
    "             #y_mean = np.mean(y)\n",
    "             #self.label = (self.label-y_mean)/y_std\n",
    "            for i in range(len(self.data[0])):\n",
    "                mean_list.append(np.mean(self.data[:,i]))\n",
    "                std_list.append(np.std(self.data[:,i]))\n",
    "                self.data[:,i]=(self.data[:,i]-np.mean(self.data[:,i]))/(np.std(self.data[:,i])+1e-8)\n",
    "            # mean_list.append(y_mean)\n",
    "            # std_list.append(y_std)\n",
    "            self.value=torch.rand(self.data.shape[0]-SEQ_LEN,SEQ_LEN,self.data.shape[1])\n",
    "            for i in range(self.data.shape[0]-SEQ_LEN):                  \n",
    "                self.value[i,:,:]=torch.from_numpy(self.data[i:i+SEQ_LEN,:].reshape(SEQ_LEN,self.data.shape[1]))   \n",
    "                self.label[i,:]=self.data[i+SEQ_LEN,0] \n",
    "            self.data=self.value\n",
    "        else:\n",
    "            test_path=\"stock_daily/stock_test.csv\"\n",
    "            with open(test_path) as f:\n",
    "                self.data = np.genfromtxt(f,delimiter = \",\")\n",
    "                #addi=np.zeros((self.data.shape[0],1))\n",
    "                #self.data=np.concatenate((self.data,addi),axis=1)\n",
    "                self.data=self.data[:,1:5]\n",
    "            #for i in range(self.data.shape[0]-SEQ_LEN):\n",
    "            #    self.data[i+SEQ_LEN,1]=(sum(self.data[i+SEQ_LEN:i+SEQ_LEN+N_Pre,1])/N_Pre-self.data[i+SEQ_LEN-1,1])/self.data[i+SEQ_LEN-1,1]\n",
    "            #    self.data[i+SEQ_LEN,2]=(sum(self.data[i+SEQ_LEN:i+SEQ_LEN+N_Pre,2])/N_Pre-self.data[i+SEQ_LEN-1,2])/self.data[i+SEQ_LEN-1,2]\n",
    "            self.label=torch.rand(self.data.shape[0]-SEQ_LEN,1)           \n",
    "            #for i in range(self.data.shape[0]-SEQ_LEN):\n",
    "            #    self.label[i,:]=(np.mean(self.data[i+SEQ_LEN:i+SEQ_LEN+N_Pre,0])-self.data[i+SEQ_LEN-1,0])/self.data[i+SEQ_LEN-1,0]\n",
    "            #self.label = (self.label-mean_list[len(self.data[0])])/std_list[len(self.data[0])]\n",
    "            for i in range(len(self.data[0])):\n",
    "                self.data[:,i]=(self.data[:,i]-mean_list[i])/(std_list[i]+1e-8)\n",
    "            self.value=torch.rand(self.data.shape[0]-SEQ_LEN,SEQ_LEN,self.data.shape[1])\n",
    "            for i in range(self.data.shape[0]-SEQ_LEN):                  \n",
    "                self.value[i,:,:]=torch.from_numpy(self.data[i:i+SEQ_LEN,:].reshape(SEQ_LEN,self.data.shape[1]))    \n",
    "                self.label[i,:]=self.data[i+SEQ_LEN,0]\n",
    "            self.data=self.value\n",
    "    def __getitem__(self,index):\n",
    "        return self.data[index],self.label[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data[:,0])\n",
    "\n",
    "\n",
    "# In[388]:\n",
    "\n",
    "\n",
    "stock_train=Stock_Data(train=True)\n",
    "stock_test=Stock_Data(train=False)\n",
    "\n",
    "#LSTM模型\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,dimension):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.lstm=nn.LSTM(input_size=dimension,hidden_size=128,num_layers=3,batch_first=True)\n",
    "        self.linear1=nn.Linear(in_features=128,out_features=16)\n",
    "        self.linear2=nn.Linear(16,1)\n",
    "    def forward(self,x):\n",
    "        out,_=self.lstm(x)\n",
    "        x=out[:,-1,:]        \n",
    "        x=self.linear1(x)\n",
    "        x=self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# In[391]:\n",
    "\n",
    "\n",
    "#传入tensor进行位置编码\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,d_model,max_len=SEQ_LEN):\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "        #序列长度，dimension d_model\n",
    "        pe=torch.zeros(max_len,d_model)\n",
    "        position=torch.arange(0,max_len,dtype=torch.float).unsqueeze(1)\n",
    "        div_term=torch.exp(torch.arange(0,d_model,2).float()*(-math.log(10000.0)/d_model))\n",
    "        pe[:,0::2]=torch.sin(position*div_term)\n",
    "        pe[:,1::2]=torch.cos(position*div_term)\n",
    "        pe=pe.unsqueeze(0).transpose(0,1)\n",
    "        self.register_buffer('pe',pe)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return x+self.pe[:x.size(0),:]\n",
    "\n",
    "\n",
    "# In[392]:\n",
    "\n",
    "\n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self,feature_size=4,num_layers=6,dropout=0.1):\n",
    "        super(TransAm,self).__init__()\n",
    "        self.model_type='Transformer'\n",
    "        self.src_mask=None\n",
    "        self.pos_encoder=PositionalEncoding(feature_size)\n",
    "        self.encoder_layer=nn.TransformerEncoderLayer(d_model=feature_size,nhead=4,dropout=dropout)\n",
    "        self.transformer_encoder=nn.TransformerEncoder(self.encoder_layer,num_layers=num_layers)\n",
    "        #全连接层代替decoder\n",
    "        self.decoder=nn.Linear(feature_size,1)\n",
    "        self.linear1=nn.Linear(SEQ_LEN,1)\n",
    "        self.init_weights()\n",
    "        self.src_key_padding_mask=None\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange=0.1\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange,initrange)\n",
    "        \n",
    "    def forward(self,src,seq_len=SEQ_LEN):       \n",
    "        src=self.pos_encoder(src)\n",
    "        #print(src)\n",
    "        #print(self.src_mask)\n",
    "        #print(self.src_key_padding_mask)\n",
    "        #output=self.transformer_encoder(src,self.src_mask,self.src_key_padding_mask)\n",
    "        output=self.transformer_encoder(src)\n",
    "        output=self.decoder(output)\n",
    "        output=np.squeeze(output)\n",
    "        output=self.linear1(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# In[394]:\n",
    "\n",
    "lstm_path=\"./model_lstm/epoch_\"\n",
    "transformer_path=\"./model_transformer/epoch_\"\n",
    "# save_path=lstm_path\n",
    "save_path=transformer_path\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    global loss_list\n",
    "    global iteration\n",
    "    dataloader=DataLoader(dataset=stock_train,batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
    "    for i,(data,label) in enumerate(dataloader):\n",
    "        iteration=iteration+1\n",
    "        data,label = data.to(device),label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output=model.forward(data)\n",
    "        loss=criterion(output,label)\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        if i%20==0:\n",
    "            loss_list.append(loss.item())\n",
    "            print(\"epoch=\",epoch,\"iteration=\",iteration,\"loss=\",loss.item())\n",
    "        if epoch%EPOCH==0:\n",
    "            torch.save(model.state_dict,save_path+str(epoch)+\"_Model.pkl\")\n",
    "            torch.save(optimizer.state_dict,save_path+str(epoch)+\"_Optimizer.pkl\")\n",
    "\n",
    "\n",
    "# In[395]:\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    global accuracy_list\n",
    "    global predict_list\n",
    "    dataloader=DataLoader(dataset=stock_test,batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
    "    for i,(data,label) in enumerate(dataloader):\n",
    "        with torch.no_grad():            \n",
    "            data,label=data.to(device),label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predict=model.forward(data)\n",
    "            predict_list.append(predict)\n",
    "            loss=criterion(predict,label)\n",
    "            accuracy_fn=nn.MSELoss()\n",
    "            accuracy=accuracy_fn(predict,label)\n",
    "            accuracy_list.append(accuracy.item())\n",
    "    print(\"test_data MSELoss:(pred-real)/real=\",np.mean(accuracy_list))\n",
    "\n",
    "\n",
    "# In[396]:\n",
    "\n",
    "\n",
    "def loss_curve(loss_list):\n",
    "    x=np.linspace(1,len(loss_list),len(loss_list))\n",
    "    x=20*x\n",
    "    plt.cla()  # 清除axes，即当前 figure 中的活动的axes，但其他axes保持不变。\n",
    "    plt.clf()  # 清除当前 figure 的所有axes，但是不关闭这个 window，所以能继续复用于其他的 plot\n",
    "    plt.plot(x,np.array(loss_list),label=\"train_loss\")\n",
    "    plt.ylabel(\"MSELoss\")\n",
    "    plt.xlabel(\"iteration\")\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(\"train_loss.png\",dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# In[397]:\n",
    "\n",
    "\n",
    "def contrast_lines(predict_list):\n",
    "    real_list=[]\n",
    "    prediction_list=[]\n",
    "    dataloader=DataLoader(dataset=stock_test,batch_size=4,shuffle=False,drop_last=True)\n",
    "    date=[]\n",
    "    for i,(data,label) in enumerate(dataloader):\n",
    "        for idx in range(BATCH_SIZE):\n",
    "            real_list.append(np.array(label[idx]*std_list[0]+mean_list[0]))\n",
    "            #real_list.append(np.array(label[idx]))\n",
    "            date.append(data[idx][0])\n",
    "    for item in predict_list:\n",
    "        item=item.to(\"cpu\")\n",
    "        for idx in range(BATCH_SIZE):\n",
    "            prediction_list.append(np.array(item[idx]*std_list[0]+mean_list[0]))\n",
    "            #prediction_list.append(np.array((item[idx])))\n",
    "    x=np.linspace(1,len(real_list),len(real_list))\n",
    "    plt.cla()  # 清除axes，即当前 figure 中的活动的axes，但其他axes保持不变。\n",
    "    plt.clf()  # 清除当前 figure 的所有axes，但是不关闭这个 window，所以能继续复用于其他的 plot\n",
    "    plt.plot(x,np.array(real_list),label=\"real\")\n",
    "    plt.plot(x,np.array(prediction_list),label=\"prediction\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"transformer_Pre.png\",dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#选择模型为LSTM或Transformer，注释掉一个\n",
    "\n",
    "#model=LSTM(dimension=4)\n",
    "#save_path=lstm_path\n",
    "model=TransAm(feature_size=4)\n",
    "save_path=transformer_path\n",
    "\n",
    "model=model.to(device)\n",
    "criterion=nn.MSELoss()\n",
    "\n",
    "#if os.path.exists(\"./model_lstm/LSTM_\"+str(EPOCH)+\"_Model.pkl\"):\n",
    "#    model.load_state_dict(torch.load(\"./model_lstm/epoch_\"+str(EPOCH)+\"_Model.pkl\"))\n",
    "#optimizer=optim.Adam(model.parameters(),lr=LEARNING_RATE)\n",
    "#if os.path.exists(\"./model_lstm/LSTM_\"+str(EPOCH)+\"_Optimizer.pkl\"):\n",
    "#    optimizer.load_state_dict(torch.load(\"./model_lstm/epoch_\"+str(EPOCH)+\"_Optimizer.pkl\"))\n",
    "\n",
    "if os.path.exists(\"./model_transformer/TRANSFORMER_\"+str(EPOCH)+\"_Model.pkl\"):\n",
    "    model.load_state_dict(torch.load(\"./model_transformer/epoch_\"+str(EPOCH)+\"_Model.pkl\"))\n",
    "optimizer=optim.Adam(model.parameters(),lr=LEARNING_RATE)\n",
    "if os.path.exists(\"./model_transformer/TRANSFORMER_\"+str(EPOCH)+\"_Optimizer.pkl\"):\n",
    "    optimizer.load_state_dict(torch.load(\"./model_transformer/epoch_\"+str(EPOCH)+\"_Optimizer.pkl\"))\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    symbol = '00069'\n",
    "    period = 50\n",
    "    data = import_csv(symbol)\n",
    "    # df_draw=data[-period:]\n",
    "    # draw_Kline(df_draw,period,symbol)\n",
    "    data.drop(['Num','Date'],axis=1,inplace = True)    \n",
    "    iteration=0\n",
    "    loss_list=[]\n",
    "    #开始训练神经网络\n",
    "    for epoch in range(1,EPOCH+1):\n",
    "        predict_list=[]\n",
    "        accuracy_list=[]\n",
    "        train(epoch)\n",
    "        test()\n",
    "    #绘制损失函数下降曲线    \n",
    "    loss_curve(loss_list)\n",
    "\n",
    "#In[]\n",
    "#绘制测试集pred-real对比曲线\n",
    "contrast_lines(predict_list)\n",
    "# %%\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
